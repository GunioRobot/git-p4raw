#!/usr/bin/perl

use strict vars, subs;
use warnings;
use Scriptalicious;
use FindBin qw($Bin);
use List::Util qw(sum max);
use Scalar::Util qw(looks_like_number);
use Data::Dumper;
use DBI;
use Cwd;
use IO::Handle;
use File::Path qw(rmtree);
use Fatal qw(:void open);
use Digest::SHA1;

use vars qw($SHARE $SCRIPT_MODE);
$SHARE = $Bin;

sub do_init {
	my $dbh = shift;
	run("git", "init");
	run("git", "config", "p4raw.source", getcwd);
	$dbh->begin_work;
	say "Setting up tables on DB ".$dbh->{pg_db}." (in a transaction)";
	open SQL, "<$SHARE/tables.sql" or die $!;
	my $statements = join "", <SQL>;
	close SQL;
	mutter "Running: $statements";
	eval {
		local($dbh->{PrintError});
		$dbh->do($statements);
		$dbh->commit;
	};
	if ( $@ ) {
		my $msg = $@;
		chomp($msg);
		$dbh->rollback;
		barf "couldn't set up tables - already setup? ($msg)";
	}
	say "Set up DB OK";
}

sub do_drop {
	my $dbh = shift;
	open SQL, "<$SHARE/tables.sql" or die $!;
	my $statements = join ";\n", reverse
		map { (m{create (table|sequence) (\S+)}
		       ? ("drop $1 $2") : ()) } <SQL>;
	close SQL;
	mutter "Running: $statements";
	$dbh->begin_work;
	$dbh->do("set constraints all deferred");
	$dbh->do($statements);
	$dbh->commit;
	say "Dropped DB OK";
	my $git_dir = capture("git", "rev-parse", "--git-dir");
	my $source = capture("git", "config", "p4raw.source");
	if ( $source ) {
		if ( $source eq getcwd ) {
			rmtree($git_dir);
		}
		else {
			moan("source is '$source', not ".getcwd
			     ."; rm -rf $git_dir yourself");
		}
	}
	else {
		moan "no p4raw.source; not removing no git dir";
	}
}

sub do_load {
	my $dbh = shift;
	my @files;
	if ( @_ ) {
		@files = @_;
	}
	else {
		@files = grep { -f }
			(<journal checkpoint journal.*.gz checkpoint.*.gz>,
			 <p4raw-extra-*.asv>);
	}
	while ( my $filename = shift @files ) {
		say "loading data from $filename";
		start_timer;
		if ( $filename =~ m{\.gz$} ) {
			$filename = "zcat $filename|";
		}
		my %wanted =
			( "db.desc" => "change_desc",
			  "db.integed" => "integed",
			  "db.change" => "change",
			  "db.revcx" => "revcx",
			  "db.user" => "p4user",
			  "db.rev" => "rev",
			  "db.label" => "label",
			);
		my %sth;
		my $get_sth = sub {
			my ($table, $size)=@_;
			$sth{$table."\0".$size} ||= do {
				my $sql = "INSERT INTO $table "
					."VALUES (".join(",",("?")x$size).")";
				whisper "Preparing: $sql";
				$dbh->prepare($sql);
			};
		};
		my $wanted_re = join "|", keys %wanted;
		my $regex_wanted = qr/(?:$wanted_re)/;
		open JOURNAL, "$filename" or die $!;
		#binmode JOURNAL, ":encoding(iso-8859-1)";
		my ($rows, $dirty, $dirty_rows);
		$dbh->begin_work;
		$dbh->{AutoCommit} = 0;
		$dbh->{PrintError} = 0;
		my %count;
		while ( <JOURNAL> ) {
			next unless m{^\@pv\@\s\d+\s@($regex_wanted)@};
			my $db = $wanted{$1};
			my @columns;
			while ( (pos($_)||0)+1 < length $_ ) {
				my $pre = pos $_;
				my $ok = m{\G(?:\@((?:[^@]+|\@\@)*)\@|(-?\w+))\s}g;
				if ( !$ok ) {
					pos($_) = $pre;
				}
				my ($string, $token) = ($1, $2) if $ok;
				if ( defined $string ) {
					$string =~ s{\@\@}{\@}g;
					utf8::upgrade($string);
					push @columns, $string;
				}
				elsif ( defined $token ) {
					push @columns, $token;
				}
				else {
					die "end of file; $_" if eof JOURNAL;
					my $p = pos $_;
					pos($_)=0;
					my $line;
					my @extra;
					do {
						$line = readline JOURNAL;
						push @extra, $line;
					} until ($line =~ m{@\s*$});
					$_.=join("",@extra);
					pos($_) = $p;
					redo;
				}
			}
			@columns = (@columns[3..$#columns]);
			my $sth = $get_sth->($db,scalar(@columns));
			eval {
				$sth->execute(@columns);
				$rows++;
				$dirty_rows++;
				$dirty+=sum map { length } @columns;
				if ( $VERBOSE > 1 ) {
					print "Saved: $columns[0]\n";
				}
			};
			if ( $@ ) {
				barf "DBI error ($@); Data: ".Dumper(\@columns);
			}
			$count{$db}++;
			if ( $dirty > (1<<18) or $dirty_rows >= 5000 ) {
				say "commit after $rows rows: ".
					join("; ", map{"$count{$_} x $_"}
					     keys %count);
				%count=();
				$dirty = 0;
				$dirty_rows = 0;
				$dbh->commit;
				$dbh->begin_work;
			}
		}
		$dbh->commit;
		$dbh->{AutoCommit} = 1;
		say "Loaded $rows rows from $filename in ".show_elapsed;
	}
}

sub _to_p4_journal_format {
	my $db_name = shift;
	return
		((join " ", map {
			my $x = $_;
			if ( looks_like_number $x ) {
				$x
			}
			else {
				$x =~ s{\@}{\@\@}g;
				"\@$x\@"
			}
		} ("pv", 3, "db.$db_name", @_))."\n");
}

sub _journal_p4_row {
	my $statefile = shift;
	my $table = shift;
	my $mode = ( -e $statefile ? ">>" : ">" );
	open JOURNAL, $mode, $statefile;
	print JOURNAL _to_p4_journal_format $table, @_;
	close JOURNAL;
}

sub add_p4users {
	my $dbh = shift;
	my $data = shift;
	my $statefile = "p4raw-extra-users.asv";
	for my $datum ( @$data ) {
		my ($who, $count) = @$datum;
		say "$who made $count changes";
		my ($realname, $email);
		do {
			$realname = prompt_string
				"Who was using this '$who' moniker?", $realname;
			say "'$realname' huh.  Ok.";
			$email = prompt_string
				("And what was (or is) their e-mail address?",
				 $email);
			say "Right, so I'll attribute commits from that usercode "
				."to $realname <$email>";
		} until ( prompt_Yn("Sound good?") );
		_journal_p4_row $statefile, "user",
			($who, $email, "", time, time,
			 $realname, "", 0, "", 0);
	}
	return $statefile;
}

sub do_check {
	my $dbh = shift;

	if ( $VERBOSE > 0 ) {
		require Text::CSV_XS;
	}

	open SQL, "<$SHARE/constraints.sql" or die $!;
	my $constraints = join "", <SQL>;
	close SQL;
	my $do_this;

	while ( $constraints =~ m{\G(?: ( \s* --(?-s:.*)
					  (?: \n\s*--(?-s:.*) )* )
			            | \s* (.*?) (?:;|\Z) ) }sgx ) {
		my ($comment, $sql) = ($1, $2);
		if ( $comment ) {
			$comment =~ s{^\s*--\s*}{}mg;
			if ( $comment =~ s{^FOUND: (.*)}{}ms ) {
				$do_this = $1;
			}
			else {
				undef($do_this);
			}
			say $comment;
		}
		elsif ( $sql ) {
			$sql =~ s{^\s*}{}s;
			if ( $sql =~ m{^select}i ) {
				mutter "query: $sql";
				my $sth = $dbh->prepare($sql);
				$sth->execute;
				my $csv;
				if ( $VERBOSE > 0 ) {
					$csv = Text::CSV_XS->new
						({binary => 1,
						  eol => "\n"});
					my @N = @{ $sth->{NAME} };
					$csv->print(\*STDOUT, \@N);
				}
				my $rows = 0;
				my @data;
				while ( my @row = $sth->fetchrow_array ) {
					if ( $csv ) {
						$csv->print(\*STDOUT, \@row)
							or barf $csv->error;
					}
					if ( $do_this ) {
						push @data, \@row;
					}
					$rows++;
				}
				say "($rows rows".
					($rows&&$VERBOSE==0?"; use -v to see them"
					 :"").")";
				if ( $do_this and $rows ) {
					no strict 'refs';
					my $statefile =
						&{"$do_this"}($dbh, \@data);
					if ( $statefile ) {
						eval {
							do_load($dbh, $statefile);
						};
						moan("load of new data failed; $@")
							if $@;
					}
				}
			}
			else {
				mutter "running: $sql";
				eval { local($dbh->{PrintError});
				       $dbh->do($sql) };
				if ( $@ ) {
					my $x = $@;
					chomp($x);
					say "error from DB ($x), continuing"
						unless $x =~ m{already exists};
				}
			}
		}
	}
}

sub do_find_change {
	my $dbh = shift;
	my $rev = shift;
	$rev or abort "no revision passed to find-change";

	if ( $rev =~ m{^\d{1,6}$} ) {
		show_git_paths($dbh, $rev);
	}
	elsif ( $rev =~ m{^[a-f0-9]{40}$} ) {
		show_p4_change($dbh, $rev);
	}
	else {
		my ($rc, $revision) = capture_err
			(-out2 => "/dev/null",
			 qw(git rev-parse --verify), $rev);

		if ( $? ) {
			barf "'$rev' is not a valid revision";
		}
		chomp($revision);
		show_p4_change($dbh, $revision);
	}
}

sub show_p4_change {
	my $dbh = shift;
	my $git_rev = shift;

	my $query = $dbh->prepare(<<SQL);
select
	change,
	branchpath
from
	change_commits
where
	commitid = ?
SQL
	$query->execute($git_rev);
	my $x = $query->fetchrow_hashref;
	$query->finish;

	if ( !$SCRIPT_MODE ) {
		if ( $x ) {
			say "commit ".substr($git_rev, 0, 12)
				.(" is Change $x->{change} on branch "
				  .$x->{branchpath});
		}
		else {
			barf "commit $git_rev not found in DB";
		}
	}
	else {
		if ( $x ) {
			print "$x->{change},$x->{branchpath}\n";
		}
		else {
			exit 1;
		}
	}
}

sub show_git_paths {
	my $dbh = shift;
	my $change = shift;

	my $query = $dbh->prepare(<<SQL);
select
	commitid,
	branchpath
from
	change_commits
where
	change = ?
SQL
	$query->execute($change);
	my @d;
	while ( my $x = $query->fetchrow_hashref ) {
		push @d, $x;
	}
	$query->finish;

	if ( !$SCRIPT_MODE) {
		if ( @d > 1 ) {
			say "change $change affected multiple branches:";
			for ( @d ) {
				print "branch $_->{branchpath}, see "
					."commit $_->{commitid}\n";
			}
		}
		elsif ( @d ) {
			say "change $change was on branch "
				.("$d[0]{branchpath}, see commit "
				  .$d[0]{commitid}."\n");
		}
		else {
			barf "change $change not found in DB.  perhaps it was cancelled?";
		}
	}
	else {
		if ( @d ) {
			print "$_->{commitid},$_->{branchpath}\n"
				for @d;
		}
		else {
			exit 1;
		}
	}
}


sub do_filelog {
	my $dbh = shift;
	my %filelog_opts;
	{
		@ARGV = @_;
		getopt("i" => \$filelog_opts{follow_branches},
		       "t" => \$filelog_opts{show_time},
		       "l" => \$filelog_opts{show_desc},
		       "L" => \$filelog_opts{show_some_desc},
		       "m=i" => \$filelog_opts{maxRevs},
		      );
		@_ = @ARGV;
	}

	my ($follow_branches, $show_type, $show_desc, $show_some_desc,
	    $maxRevs);
	my @placeholders;
	my $pathspec = shift;
	my ($depotpath, $rev) = ($pathspec =~ m{^(.*?)(?:#(\d+))?$});

	show_filelogs($dbh, $depotpath, $rev, \%filelog_opts);
}

sub _p4_disp_rev {
	my $low = shift;
	my $high = shift;
	$low++;
	($low == $high ? "#$high" : "#$low,#$high");
}

# this function converts a perforce type bitmap to a text type.  I
# didn't try very hard to understand the layout or make this function
# very clever, I just cared about the types I saw in my own test
# repository.
use constant P4_TYPE_EXEC => 0b10_0000_0000;
sub _p4_type {
	my $type = shift;
	my @supp;
	if ($type & 4096) {
       		$type ^= 4096;
		push @supp, "+w";
	}
	return join "",
		($type ==              0 ? "text"     :
		$type ==   0b1_0000_0011 ? "binary"   :
		$type ==   0b1_0000_0001 ? "ubinary"  :
		$type ==    P4_TYPE_EXEC ? "xtext"    :
		$type ==  0b00_0010_0000 ? "ktext"    :
		$type ==  0b10_0010_0000 ? "kxtext"   :
		$type ==  0b01_0000_0000 ? "binary+D" :
		$type ==0b1101_0000_0011 ? "apple"    :
		$type == 0b100_0000_0000 ? "symlink"  : "xxx-".sprintf("%b",$type)),
		@supp;
}

sub _p4_changelog {
	my $row = shift;
	my $o = shift || {};
	my @rv = ("$row->{change} ",
		  (defined $row->{change_type}
		   ? ($row->{change_type}, " ") : ()),
		  "on $row->{when} by $row->{who_user}",
		  "\@$row->{who_host}",
		  ($row->{file_type}
		   ? (" (",_p4_type($row->{file_type}), ")") : ()));

	if ( $o->{show_desc} || $o->{show_some_desc} ) {
		push @rv, "\n\n",
			(map { "\t$_\n" }
			 split /\n/,
			 ( $o->{show_some_desc}
			   ? substr $row->{description}, 0, 250
			   : $row->{description} ));
		push @rv, "\n";
	}
	else {
		my $short = $row->{short_desc};
		$short =~ s{\s}{ }g;
		push @rv, " '$short'\n";
	}
	@rv;
}

sub show_filelogs {
	my $dbh = shift;
	my $depotpath = shift;
	my $rev = shift;
	my $o = shift;

	# build the query.
	my @placeholders;

	my $time_fmt = 'YYYY/MM/DD';
	if ( $o->{show_time} ) {
		$time_fmt .= ' HH:MI:SS';
	}
	push @placeholders, $time_fmt, $depotpath;

	my $revision_clause = '';
	if ( $rev ) {
		$revision_clause = 'and revision <= ?';
		push @placeholders, $rev;
	}

	my $limit_clause = '';
	if ( $o->{maxRevs}) {
		$limit_clause = "limit ?";
		push @placeholders, $o->{maxRevs};
	}

	my $x = $o->{select_extra}||"";

	my $output = $o->{output_func};
	if ( !$output ) {
		$output = sub {
			my $row = shift;
			my $ii = shift;
			print "... #$row->{revision} change ",
				_p4_changelog($row, $o);
			while ( my $i = $ii->() ) {
				my $other;
				my ($low, $high);
				if ( $i->{subject} eq $row->{depotpath} ) {
					$other = $i->{object};
					($low, $high) = @{$i}{
						qw(object_minrev
						   object_maxrev)};
				}
				else {
					$other = $i->{subject};
					($low, $high) = @{$i}{
						qw(subject_minrev
						   subject_maxrev)};
				}
				my $disp_rev = _p4_disp_rev($low, $high);
				print "... ... $i->{int_title} $other",
					"$disp_rev\n";
			}
		};
	}
	my $oh = $o->{output_header} || sub {
		print "$depotpath\n";
	};
	my $long_desc = "";
	my $desc_join = "";
	if ( $o->{show_desc} or $o->{show_some_desc} ) {
		$long_desc = "\tchange_desc.description,";
		$desc_join = "\tleft join change_desc\n"
			."\t\tusing (change_desc_id)";
	}

	my $sql = <<SQL;
select
$long_desc
$x
	to_char(to_timestamp(change_time), ?) as when,
	*
from
	revcx_path
$desc_join
where
	depotpath = ? $revision_clause
order by
	revision desc
$limit_clause
SQL
	whisper "running: $sql";
	my $query = $dbh->prepare($sql);
	$query->execute(@placeholders);

	my $integed_fetch = $dbh->prepare(<<SQL);
select
	integed.*,
	int_type.title as int_title
from
	integed
	inner join int_type
		using (int_type)
where
	(subject = ? and subject_maxrev = ?)
	-- or (object = ? and object_maxrev = ?)
order by
	object, object_maxrev desc
SQL
	$oh->();
	while ( my $row = $query->fetchrow_hashref ) {
		my $executed;
		my $int_rows_iter = sub {
			$integed_fetch->execute
				($depotpath, $row->{revision})
					unless $executed++;
			$integed_fetch->fetchrow_hashref;
		};
		$output->($row, $int_rows_iter);
	}
}

sub do_integrated {
	my $dbh = shift;
	my %integed_opts;
	{
		@ARGV = @_;
		getopt("r" => \$integed_opts{reverse},
		      );
		@_ = @ARGV;
	}

	my $depotpath = shift;

	show_integes($dbh, $depotpath, \%integed_opts);
}

sub show_integes {
	my $dbh = shift;
	my $depotpath = shift;
	my $o = shift;

	my $which = "subject";
	if ( $o->{reverse} ) {
		$which = "object";
	}

	my $output = $o->{output} || sub {
		my $row = shift;
		my $subj_dr = _p4_disp_rev
			($row->{subject_minrev}, $row->{subject_maxrev});
		my $obj_dr = _p4_disp_rev
			($row->{object_minrev}, $row->{object_maxrev});

		print "$row->{subject}$subj_dr - ",
			("$row->{int_title} $row->{object}$obj_dr",
			 "\n");
	};

	my $sth = $dbh->prepare(<<SQL);
select
	integed.*,
	int_type.title as int_title
from
	integed
	inner join int_type
		using (int_type)
where
	$which = ?
order by
	object,
	object_minrev,
	subject_maxrev
SQL

	$sth->execute($depotpath);

	while ( my $row = $sth->fetchrow_hashref ) {
		$output->($row);
	}
}

sub do_describe {
	my $dbh = shift;

	my %desc_opts;
	{
		@ARGV = @_;
		getopt( "l" => \$desc_opts{long},
		      );
		@_ = @ARGV;
	}
	abort "no change passed to describe" if !@_;

	my $change = shift;
	if ( $change !~ m{^\d+$} ) {
		abort "'$change' is not a valid change number";
	}

	change_stats($dbh, $change, \%desc_opts);
}

use POSIX qw(strftime);

sub change_stats {
	my $dbh = shift;
	my $change = shift;
	my $o = shift;

	my $csv;
	my (%paths, @revcxs);
	my $output = $o->{output} || sub {
		my $row = shift;

		# try to figure out the branch root by looking for top
		# level changes, or integrates from other paths.  Hope
		# no integrations are happening between files with
		# different names!
		my $path = $row->{depotpath};
		$path =~ s{/[^/]*$}{};
		if ( $row->{int_obj} ) {
			$path = diff_right($row->{int_obj},
					   $row->{depotpath});
		}
		$paths{$path}++;
		push @revcxs, $row;
	};

	my $show_header = $o->{show_header} || sub {
		my $d = shift;
		print "Change $d->{change} by $d->{who_user}\@",
			("$d->{who_host} on ",
			 strftime("%Y/%m/%d %H:%M:%S",
				   localtime($d->{change_time})),
			 "\n");
		print "\n";
		print map { "\t$_\n" } split "\n", $d->{description};
		print "\n";
	};

	my $finish = $o->{finish} || sub {
		my (%by_path);
		# eliminate the paths that shadow others.
		my $path;
		for $path ( sort { length($a) <=> length($b) }
			       keys %paths ) {
			next unless $paths{$path};
			my @gonners = grep m{^\Q$path\E/}, keys %paths;
			delete @paths{@gonners};
		}
		my $path_re = join("|",map{"\Q$_\E"} keys %paths);
		for my $row (@revcxs ) {
			($path) = ($row->{depotpath} =~ m{^($path_re)/})
				or die "got confused.  depotpath = "
					.("$row->{depotpath}, looking "
					  ."for $path_re");
			push @{ $by_path{$path} ||= [] },
				$row;
		};
		for $path ( sort keys %by_path ) {
			print "On path $path,\n";
			show_changes_detail($o, $path, @{$by_path{$path}});
		}
	};

	my $sth = $dbh->prepare(<<SQL);
select
	*
from
	change_desc
	inner join change
		using (change_desc_id)
where
	change.change = ?
SQL
	$sth->execute($change);
	$show_header->($sth->fetchrow_hashref);
	$sth->finish;

	$sth = $dbh->prepare(<<SQL);
select
	*,
        int_type.title as int_title,
	change_type.title as change_title
from
	revcx_integed
	inner join change_type
		using (change_type)
	left join int_type
		on (int_obj_type = int_type)
where
	change = ?
order by
	depotpath
SQL
	$sth->execute($change);
	while ( my $row = $sth->fetchrow_hashref ) {
		$output->($row);
	}
	$finish->();
}

sub show_changes_detail {
	my $o = shift;
	my $path = shift;
	for my $ct ( 0..4 ) {
		my @ct = grep { $_->{change_type} == $ct } @_;

		my %by_object_path;
		for my $chg ( @ct ) {
			my $op = "";
			if ( $chg->{int_obj} ) {
				$op = diff_right($chg->{depotpath},
						 $chg->{int_obj});
			}
			push @{ $by_object_path{$op} ||= [] }, $chg;
		}

		for my $obj_path ( sort keys %by_object_path ) {
			my $chgs = $by_object_path{$obj_path};
			print "\t";
			print $ct[0]{change_title};
			print " ";
			if ( $obj_path ) {
				my %changes;
				my $headrev =
					!(grep {
						!$_->{int_subj_headrev}
					} @$chgs);
				my $change =
					max map {
						$_->{int_subj_max_change}
					} @$chgs;
				print "from $obj_path ("
					.($headrev?"head":$change)."), ";
			}
			print scalar(@$chgs)," file(s)";
			print "\n";
			if ( $o->{long} ) {
				for my $c ( @$chgs ) {
					show_chg($o, $path, $c);
				}
			}
		}
	}
}

sub show_chg {
	my $o = shift;
	my $path = shift;
	my $chg = shift;

	print "\t\t";
	my $filename = substr $chg->{depotpath}, length $path;
	if ( $chg->{int_title} ) {
		my $odr = _p4_disp_rev
			($chg->{int_obj_min}, $chg->{int_obj_max});
		my $sdr = _p4_disp_rev
			($chg->{int_subj_min}, $chg->{int_subj_max});
		if ( $sdr =~ m{,} ) {
			$sdr .= " ($chg->{int_subj_min_change},"
				."$chg->{int_subj_max_change})";
		}
		else {
			$sdr .= " ($chg->{int_subj_max_change})";
		}
		if ( $chg->{int_subj_headrev} ) {
			$sdr .= "(HEAD)";
		}

		print "...$filename: $sdr $chg->{int_title} $odr\n";
	}
	else {
		print "...$filename\n";
	}
}

sub diff_right {
	my $left = shift;
	my $right = shift;
	my $done = 0;
	while (!$done) {
		my ($last_component) = $left =~ m{(/[^/]+)$};

		if (!defined($last_component) or
			$right !~ s{\Q$last_component\E$}{}) {

			$done = 1;
		}
		else {
			$left =~ s{\Q$last_component\E$}{};
		}
	}
	return $right;
}

sub do_changes {
	my $dbh = shift;
	my %changes_opts;
	{
		@ARGV = @_;
		getopt("l" => \$changes_opts{show_desc},
		       "L" => \$changes_opts{show_some_desc},
		       "m=i" => \$changes_opts{maxRevs},
		      );
		@_ = @ARGV;
	}

	my $pathspec = shift;
	my ($depotpath, $minRev, $maxRev)
		= ($pathspec =~ m{^(.*?)(?:#(\d+)(?:,#?(\d+))?)?$})
			if $pathspec;
	$maxRev = $minRev if !$maxRev;

	show_changes($dbh, $depotpath, $minRev, $maxRev, \%changes_opts);
}

sub show_changes {
	my $dbh = shift;
	my $depotpath = shift;
	my $minRev = shift;
	my $maxRev = shift;
	my $o = shift;

	my $output = $o->{output} ||= sub {
		my $row = shift;
		print "Change ", _p4_changelog($row, $o);
	};

	# build the query.  some code duplicated from show_filelogs,
	# CBA fixing for now...
	my @placeholders;

	my $time_fmt = 'YYYY/MM/DD';
	if ( $o->{show_time} ) {
		$time_fmt .= ' HH:MI:SS';
	}
	push @placeholders, $time_fmt;

	my @filters;

	my $long_desc = "";
	my $desc_join = "";
	if ( $o->{show_desc} or $o->{show_some_desc} ) {
		$long_desc = "\tchange_desc.description,";
		$desc_join = "\tleft join change_desc\n"
			."\t\tusing (change_desc_id)";
	}

	my $limit_clause = '';
	if ( $o->{maxRevs}) {
		$limit_clause = "limit ?";
		push @placeholders, $o->{maxRevs};
	}

	my $revcx_join = "";
	if ( $depotpath ) {
		$revcx_join = "\tinner join revcx\n"
			.("\t\ton (revcx.change = change.change and\n"
			  ."\t\t\trevcx.depotpath = ?)");
		push @placeholders, $depotpath;
	}

	if ( $maxRev ) {
		if ( $minRev ) {
			push @filters, 'revision between ? and ?';
			push @placeholders, $minRev, $maxRev;
		}
		else {
			push @filters, 'revision <= ?';
			push @placeholders, $maxRev;
		}
	}

	my $where_clause = "";
	if ( @filters ) {
		$where_clause = "where\n\t".join("\nand\t", @filters);
	}

	my $sql = <<SQL;
select
$long_desc
	to_char(to_timestamp(change_time), ?) as when,
	change.*
from
	change
$revcx_join
$desc_join
$where_clause
order by
	change.change desc
$limit_clause
SQL
	if ( $VERBOSE>1) {
		say "querying changes with: $sql";
		say "placeholders: (".join(", ", @placeholders).")";
	}
	my $sth = $dbh->prepare($sql);
	$sth->execute(@placeholders);
	while ( my $row = $sth->fetchrow_hashref ) {
		$output->($row);
	}
}

sub max_change {
	my $dbh = shift;
	my ($change) = map { @$_ } @{ $dbh->selectall_arrayref(<<SQL) };
select
	max(change)
from
	change
SQL
	return $change;
}

sub sha1_blob_ref {
	my $data_ref = shift;
	my $sha1 = Digest::SHA1->new;
	my $l = length($$data_ref);
	$sha1->add("blob $l\0");
	$sha1->add($$data_ref);
	return lc($sha1->hexdigest);
}

sub do_blobs {
	my $dbh = shift;
	# psuedocode for blob import.
	# 1. find the lowest change which is yet to be marked as
	#    imported
	# 2. get all of the files in it
	# 3. for each of those files, find all the ones without
	#    rev_blob rows
	# 4. for each of those files, find *all* of the branched
	#    versions of it, and send them all at once to
	#    git-fast-import, entering rev_blob rows for them as we
	#    get hashes back from git-fast-import
	#    It's quite important to do all the revisions of a file at
	#    once, otherwise fast-import will not be able to make
	#    on-the-fly deltas and the repo will become gigabytes.
	# 
	#    note "p4 print" is not required; can just use rcs
	#    directly by looking at the "rev" table; it has a rcs
	#    filename and revision that quite adequately refers to an
	#    rcs version.  So you can just collect
	#    `co -p1.2 -kb depot/mg.c` (eg), get its length, confirm
	#    the MD5, and then feed to git-fast-import using the
	#    "mark" functionality, perhaps marking it with the MD5
	#    or depotpath/revision.  Then when the fast-import
	#    "checkpoint" command is issued we will get back the
	#    GIT-SHA1 values.
	#    In fact I'd be highly tempted to parse the RCS file
	#    directly, as it might be significantly faster to hold
	#    the latest version of each RCS file in memory, as we work
	#    backwards through the revisions and construct new
	#    versions of it for feeding to fast-import.  Consider an
	#    RCS file with many revisions; getting all revisions out
	#    with `co -p` will be O(N^2) but directly will be O(N)

	# 5. finally, we have rev_blob rows for all of the files
	#    in this version, so send a tree and/or commit object
	#    (though it might be easier to use
	#    `git update-index --index-info`).  Information from the
	#    integed table should probably go into the commit message,
	#    where it is not redundant (which is a difficult criterion
	#    to nail down for sure!)
}

#=====================================================================
#  MAIN SECTION STARTS HERE
#=====================================================================
getopt("script|s" => \$SCRIPT_MODE);
if (! -t STDOUT) {
	$SCRIPT_MODE = 1;
}

binmode STDOUT, ":utf8";

my $action = shift;
abort "no action given" unless $action;
$action =~ s{-}{_}g;
abort "bad action/argument `$action'" unless defined &{"do_$action"};

my $dbh = DBI->connect("dbi:Pg:") or barf "DBI connect failed";
$dbh->{RaiseError}=1;
$dbh->{PrintError}=1;
$dbh->{AutoCommit}=1;

&{"do_$action"}($dbh, @ARGV);

__END__

=head1 NAME

git-p4raw - git fast-import exporter for RAW perforce repositories

=head1 SYNOPSIS

 # import commands:
 git-p4raw init     # to return here: git-p4raw drop
 git-p4raw load
 git-p4raw check
 git-p4raw graft CHANGE commit-ish  # configure manual reparenting
 git-p4raw import   # to return here: git-p4raw truncate

 # query commands:
 git-p4raw { find-change N | describe N | integrated DEPOTPATH
           | filelog DEPOTPATH | changes [ -l ] [ file[#range] ]
           | annotate PATH }

=head1 DESCRIPTION

B<git-p4raw> is a tool for importing perforce repositories into git,
and querying the legacy metadata in perpetuity.

It assumes you have the raw Perforce repository lying around, and does
not require the perforce server.  All you need are the C<checkpoint>,
C<journal> and RCS files.  If you want to specify things like where
the target git repository is, or which Postgres database to use, this
is configured in the normal way with environment variables
(C<GIT_DIR>, C<PGDATABASE>, etc).

=head1 COMMAND LINE OPTIONS

=over

=item B<-s, --script>

Instead of printing human-readable output, print something easily
parsable.  Automatically selected if standard output is not a terminal.

=item B<-h, --help>

Display a program usage screen and exit.

=item B<-V, --version>

Display program version and exit.

=item B<-v, --verbose>

Verbose command execution, displaying things like the
commands run, their output, etc.

=item B<-q, --quiet>

Suppress all normal program output; only display errors and
warnings.

=item B<-d, --debug>

Display output to help someone debug this script, not the
process going on.

=back

=head1 COMMANDS

=head2 IMPORT OPERATION

=over

=item C<git-p4raw init>

The first command, C<init>, initialises the database tables and git
repository.

=item C<git-p4raw drop>

C<drop> can be used to drop all database tables and destroy the git
repository, in a somewhat molly-guarded fashion.

=item C<git-p4raw load [filename...]>

The second command, C<load>, loads all of the Perforce data from the
C<checkpoint.NNN.gz> and C<journal> files which it expects to find in
the current directory (the root of the Perforce import).  You can
optionally specify which files to load from.

=item C<git-p4raw check>

This third command, C<check>, adds constraints to the database schema
and looks for errant data conditions.

If any of these constraints fail, and don't prompt to correct the data
to your satisfaction, you should investigate what is going on and
correct the data before proceeding.  The code makes assumptions that
these constraints hold.

When the command asks questions, the answers will be written to a file
called C<p4raw-extra-x.asv> in the Perforce checkpoint format (and
automatically re-loaded if you run C<load> again without arguments).

(TODO - some inconsistencies such as missing integration records are
not dealt with, and may require manual patching or use of the C<graft>
command, below)

=item C<git-p4raw graft { -d change | [ -a ] change change ... }> (TODO)

The C<graft> command is optional, and is principally for those who
want to override the decisions that this tool makes (and modifies what
is shown ahead of time using the C<describe> sub-command, see below).

If you just specify two change numbers, then the detected branch paths
for those changes is used.  Bear in mind that this detection will
frequently be wrong, unless you already have a partial conversion
underway.

When grafts are specified, they I<replace> the detected parents
completely.  Use C<-a> to add to the detected/already configured
parents.

To get around this, specify your grafting with the path as well, eg:

   git-p4raw -a //depot/perl@18 //depot/ansiperl@17

This would say that the branch at C<//depot/ansiperl> change 17 should
be added to the parents of C<//depot/perl> change 18.

If a "change" parses as a git commit ID via C<git rev-parse>, it is
treated as external to the data being imported.  Do B<not> use commit
IDs or references from previous import runs here!

The C<-d> option will reset existing grafts for a change.

This command dumps all of the configured changes to the file
F<p4raw-extra-grafts.asv> on completion, so that it can be re-loaded
should a subsequent C<git-p4raw drop> happen.  The data in this table
is unable to be checked for integrity at C<git-p4raw check> time.

=item C<git-p4raw export [ CHG[..CHG] | -n NUM ]> (TODO)

Export a bunch of changes, either bounded by a range of revisions or
the next NUM revisions, to a C<git fast-import> process.  If this
command is started with standard output as a terminal, it will start
C<git fast-import> itself.

If you start C<git fast-import>, you must take care to pass
C<--export-marks> to it if you want to perform subsequent import runs.

=back

=head2 INFORMATIONAL COMMANDS

These other commands are also mostly implemented, to show information
from the database.  Many of these commands closely correspond to their
C<p4> counterparts, though some are unique to this tool.

=over

=item C<git-p4raw find-change N>

(post-conversion) Just show the mapped git commits for a change
number.  There may be more than one if the change affected multiple
branches.  This command will be modelled on C<git-svn find-rev>, so
also be capable of showing the Perforce change number from a git
commit ID.  Currently this only looks at information in the database.

=item C<git-p4raw describe N>

Show change N vital statistics (TODO: post-conversion, mapped git
commits), and the files that were modified in that change.  A bit like
C<p4 describe -s> or C<git show --stat>.

This command performs a fairly mammoth query to determine whether
changes with lots of "integrate" changes look enough like a
cross-merge to be represented as such.  This works by looking at the
revisions of the source paths for 'integrate' changes, and then
finding out if any of those paths have new revisions between the one
that was 'integrated' and the change number in question.  It then
lists the change numbers that the revisions being integrated came
from, or "HEAD" if that was the most recent revision on that branch at
that time.  Thus, if you see output like this:

 On path //depot/perl,
         delete from //depot/relperl (HEAD), 27 file(s)
         branch from //depot/relperl (HEAD), 291 file(s)
         integrate from //depot/relperl (HEAD), 392 file(s)

Then the integration information does not contradict the assertion
that the change in question is a cross-merge from F<//depot/relperl>
to F<//depot/perl>.

However, this is not yet quite enough to prove that the integration
information in the change is a cross-merge; we also need to show that
there are changes between the I<merge base> of the two branches that
could have been merged, but are not mentioned.  That half of the
equation is currently TODO.

=item C<git-p4raw integrated DEPOTPATH>

Mimic the 'p4 integrated' command precisely, from the database
information.

With git you'd probably use something like C<gitk --all -- filename>
to show all changes that touched a particular file and their relative
ancestry.

=item C<git-p4raw filelog DEPOTPATH>

Mimic the 'p4 filelog' command precisely, from the database
information.

Again, you'd probably just use the C<gitk> file selector or perhaps
even C<git log> with the same options to show this information.  The
principle difference being you won't see things like C<copy into>,
C<branch into>, etc - only the C<from> relationships.

=item C<git-p4raw changes [ -m NUM | -l ] [ file[revRange] ]>

Mimic the 'p4 changes' command closely from the database information.

C<-m NUM> is like C<git log -NUM>, and the C<-l> is like dropping the
C<--pretty=oneline> from the concise C<git-log --pretty=oneline>
command (see also L<git-config/alias.*>).  C<git-log> also supports
adding C<file>, but the C<revRange> thing is a perforce-ism not
carried over.

The C<-i> option is basically implied by C<git-log>, so long as the
"integrate" node was a branch cross-merge.  For cherry picking, the
equivalent command will be something like C<git-log --left-right
--cherry-pick otherbranch...HEAD -- filename>, and won't see cases
where the change was picked from another change with modifications.
However, there I<will> be a note in the changelog that the file was
picked when using C<git-log>, and as a last resort there is always
this command.

=item C<git-p4raw annotate file[revRange]> (TODO)

Run C<git annotate> on the final result for the equivalent of this.
However, this command will print the (head) revisions for the given
depotpath which C<git annotate> would not normally search; this
information could be used with C<git annotate --incremental> to
produce the same results as C<p4 annotate>.

That problem goes away in practice with a changeset-based development
style, so this is mostly for getting the best annotation possible for
the current Perforce changes.

=back

As this program is not currently envisioned to support committing back
to Perforce, these commands will never be implemented, but details on
how the same thing is achieved with git follows;

=over

=item C<p4 sync>

This is something like C<git pull>, which is a C<git fetch> and a
C<git merge> in one.  However, in git you should always commit (or
stash) local changes first.

C<p4 sync -f> is very much like C<git merge -s theirs>, similarly
C<p4 sync -k> is like C<git merge -s ours>

The C<-n> option, well with git you normally just stash your changes
somewhere safe, merge and see what happens.  If you don't like it you
can C<git reset> back to where you were.  But if you like, the
plumbing command C<git read-tree -m> with a temporary "index" (read
the man page) can be used to do exactly the same thing (say, in a
script).

=item C<p4 opened>

This is very similar to the git 1.5.3+ command C<git stash list>
followed by C<git stash show>.  Or the alternate porcelain system
called "stacked git".

=item C<p4 edit>

With C<git add> you mark a file (in its current state) as belonging to
the commit/change that you are working on.  Saving files as belonging
to a particular stashed change can be done by stashing it with a new
name, pulling out the old stash and cherry picking the new stash on
top.  This is certainly one area where stacked git (currently)
provides much better command set, if less integration with
hunk-picking tools like "git gui".

=item C<p4 diff>

C<-du> is the default to C<git diff>.  You'll have to translate the
arguments to diff using the C<describe> or C<find-change>

=item C<p4 submit>

The command is C<git push>.  Assuming you have access (or maybe you're
pushing to an open access/mob branch), you can push any upstream
branch forward that has its HEAD commit in your ancestry.  So,
atomicity is enforced in that manner - if someone else pushes first,
you need to merge their commit in before pushing yours.  However you
can always push to a new branch.

Creating a new branch is not an issue; the names are considered
temporary pointers which can safely be discarded if the revision is
merged, or even thrown into a non-default ref space such as
C<refs/Attic/...> (sick sense of humour, I know) so that they don't
clutter, should the change be considered not worth preserving, or
should it get fixed up into a better change.  It can even get deleted.

=item C<p4v>

Currently the major git UIs are C<git gui> (for making commits, or
amending the last commit) and C<gitk> (for viewing/searching the
commit graph, inspecting commits, and some limited amount of changes
like cherry picking).

=back

=cut

# Local Variables:
#   mode: cperl
#   cperl-brace-offset: 0
#   cperl-continued-brace-offset: 0
#   cperl-indent-level: 8
#   cperl-label-offset: -8
#   cperl-merge-trailing-else: nil
#   cperl-continued-statement-offset: 8
# End:
